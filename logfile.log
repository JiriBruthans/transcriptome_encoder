Using device: cuda
Total parameters: 202,714,377
Trainable parameters: 102,541,577
Processed 32/15020 cells
Processed 64/15020 cells
Processed 96/15020 cells
Processed 128/15020 cells
The "stable" release is currently 2024-07-01. Specify 'census_version="2024-07-01"' in future calls to open_soma() to ensure data consistency.
Using device: cuda
Total parameters: 202,714,377
Trainable parameters: 102,541,577
Processed 64/15020 cells
Processed 128/15020 cells
Processed 192/15020 cells
Processed 256/15020 cells
Processed 320/15020 cells
Processed 384/15020 cells
Processed 448/15020 cells
Processed 512/15020 cells
Processed 576/15020 cells
Processed 640/15020 cells
Processed 704/15020 cells
Processed 768/15020 cells
Processed 832/15020 cells
Processed 896/15020 cells
Processed 960/15020 cells
Processed 1024/15020 cells
Processed 1088/15020 cells
Processed 1152/15020 cells
Processed 1216/15020 cells
Processed 1280/15020 cells
Processed 1344/15020 cells
Processed 1408/15020 cells
Processed 1472/15020 cells
Processed 1536/15020 cells
Processed 1600/15020 cells
Processed 1664/15020 cells
Processed 1728/15020 cells
Processed 1792/15020 cells
Processed 1856/15020 cells
Processed 1920/15020 cells
Processed 1984/15020 cells
Processed 2048/15020 cells
Processed 2112/15020 cells
Processed 2176/15020 cells
Processed 2240/15020 cells
Processed 2304/15020 cells
Processed 2368/15020 cells
Processed 2432/15020 cells
Processed 2496/15020 cells
Processed 2560/15020 cells
Processed 2624/15020 cells
Processed 2688/15020 cells
Processed 2752/15020 cells
Processed 2816/15020 cells
Processed 2880/15020 cells
Processed 2944/15020 cells
Processed 3008/15020 cells
Processed 3072/15020 cells
Processed 3136/15020 cells
Processed 3200/15020 cells
Processed 3264/15020 cells
Processed 3328/15020 cells
Processed 3392/15020 cells
Processed 3456/15020 cells
Processed 3520/15020 cells
Processed 3584/15020 cells
Processed 3648/15020 cells
Processed 3712/15020 cells
Processed 3776/15020 cells
Processed 3840/15020 cells
Processed 3904/15020 cells
Processed 3968/15020 cells
Processed 4032/15020 cells
Processed 4096/15020 cells
Processed 4160/15020 cells
Processed 4224/15020 cells
Processed 4288/15020 cells
Processed 4352/15020 cells
Processed 4416/15020 cells
Processed 4480/15020 cells
Processed 4544/15020 cells
Processed 4608/15020 cells
Processed 4672/15020 cells
Processed 4736/15020 cells
Processed 4800/15020 cells
Processed 4864/15020 cells
Processed 4928/15020 cells
Processed 4992/15020 cells
Processed 5056/15020 cells
Processed 5120/15020 cells
Processed 5184/15020 cells
Processed 5248/15020 cells
Processed 5312/15020 cells
Processed 5376/15020 cells
Processed 5440/15020 cells
Processed 5504/15020 cells
Processed 5568/15020 cells
Processed 5632/15020 cells
Processed 5696/15020 cells
Processed 5760/15020 cells
Processed 5824/15020 cells
Processed 5888/15020 cells
Processed 5952/15020 cells
Processed 6016/15020 cells
Processed 6080/15020 cells
Processed 6144/15020 cells
Processed 6208/15020 cells
Processed 6272/15020 cells
Processed 6336/15020 cells
Processed 6400/15020 cells
Processed 6464/15020 cells
Processed 6528/15020 cells
Processed 6592/15020 cells
Processed 6656/15020 cells
Processed 6720/15020 cells
Processed 6784/15020 cells
Processed 6848/15020 cells
Processed 6912/15020 cells
Processed 6976/15020 cells
Processed 7040/15020 cells
Processed 7104/15020 cells
Processed 7168/15020 cells
Processed 7232/15020 cells
Processed 7296/15020 cells
Processed 7360/15020 cells
Processed 7424/15020 cells
Processed 7488/15020 cells
Processed 7552/15020 cells
Processed 7616/15020 cells
Processed 7680/15020 cells
Processed 7744/15020 cells
Processed 7808/15020 cells
Processed 7872/15020 cells
Processed 7936/15020 cells
Processed 8000/15020 cells
Processed 8064/15020 cells
Processed 8128/15020 cells
Processed 8192/15020 cells
Processed 8256/15020 cells
Processed 8320/15020 cells
Processed 8384/15020 cells
Processed 8448/15020 cells
Processed 8512/15020 cells
Processed 8576/15020 cells
Processed 8640/15020 cells
Processed 8704/15020 cells
Processed 8768/15020 cells
Processed 8832/15020 cells
Processed 8896/15020 cells
Processed 8960/15020 cells
Processed 9024/15020 cells
Processed 9088/15020 cells
Processed 9152/15020 cells
Processed 9216/15020 cells
Processed 9280/15020 cells
Processed 9344/15020 cells
Processed 9408/15020 cells
Processed 9472/15020 cells
Processed 9536/15020 cells
Processed 9600/15020 cells
Processed 9664/15020 cells
Processed 9728/15020 cells
Processed 9792/15020 cells
Processed 9856/15020 cells
Processed 9920/15020 cells
Processed 9984/15020 cells
Processed 10048/15020 cells
Processed 10112/15020 cells
Processed 10176/15020 cells
Processed 10240/15020 cells
Processed 10304/15020 cells
Processed 10368/15020 cells
Processed 10432/15020 cells
Processed 10496/15020 cells
Processed 10560/15020 cells
Processed 10624/15020 cells
Processed 10688/15020 cells
Processed 10752/15020 cells
Processed 10816/15020 cells
Processed 10880/15020 cells
Processed 10944/15020 cells
Processed 11008/15020 cells
Processed 11072/15020 cells
Processed 11136/15020 cells
Processed 11200/15020 cells
Processed 11264/15020 cells
Processed 11328/15020 cells
Processed 11392/15020 cells
Processed 11456/15020 cells
Processed 11520/15020 cells
Processed 11584/15020 cells
Processed 11648/15020 cells
Processed 11712/15020 cells
Processed 11776/15020 cells
Processed 11840/15020 cells
Processed 11904/15020 cells
Processed 11968/15020 cells
Processed 12032/15020 cells
Processed 12096/15020 cells
Processed 12160/15020 cells
Processed 12224/15020 cells
Processed 12288/15020 cells
Processed 12352/15020 cells
Processed 12416/15020 cells
Processed 12480/15020 cells
Processed 12544/15020 cells
Processed 12608/15020 cells
Processed 12672/15020 cells
Processed 12736/15020 cells
Processed 12800/15020 cells
Processed 12864/15020 cells
Processed 12928/15020 cells
Processed 12992/15020 cells
Processed 13056/15020 cells
Processed 13120/15020 cells
Processed 13184/15020 cells
Processed 13248/15020 cells
Processed 13312/15020 cells
Processed 13376/15020 cells
Processed 13440/15020 cells
Processed 13504/15020 cells
Processed 13568/15020 cells
Processed 13632/15020 cells
Processed 13696/15020 cells
Processed 13760/15020 cells
Processed 13824/15020 cells
Processed 13888/15020 cells
Processed 13952/15020 cells
Processed 14016/15020 cells
Processed 14080/15020 cells
Processed 14144/15020 cells
Processed 14208/15020 cells
Processed 14272/15020 cells
Processed 14336/15020 cells
Processed 14400/15020 cells
Processed 14464/15020 cells
Processed 14528/15020 cells
Processed 14592/15020 cells
Processed 14656/15020 cells
Processed 14720/15020 cells
Processed 14784/15020 cells
Processed 14848/15020 cells
Processed 14912/15020 cells
Processed 14976/15020 cells
Processed 15040/15020 cells
Final embeddings shape: torch.Size([15020, 1280])
The "stable" release is currently 2024-07-01. Specify 'census_version="2024-07-01"' in future calls to open_soma() to ensure data consistency.
Using device: cuda
Total parameters: 202,714,377
Trainable parameters: 102,541,577
Processed 0/15020 cells
Batch processing time: 0.708s
Tokens per second: 92588.71
Processed 64/15020 cells
Batch processing time: 0.002s
Tokens per second: 33006472.98
Processed 128/15020 cells
Batch processing time: 0.002s
Tokens per second: 40257455.62
Processed 192/15020 cells
Batch processing time: 0.001s
Tokens per second: 52527786.54
Processed 256/15020 cells
Batch processing time: 0.001s
Tokens per second: 53332927.23
Processed 320/15020 cells
Batch processing time: 0.001s
Tokens per second: 54077888.44
Processed 384/15020 cells
Batch processing time: 0.001s
Tokens per second: 50650065.77
Processed 448/15020 cells
Batch processing time: 0.001s
Tokens per second: 51610572.09
Processed 512/15020 cells
Batch processing time: 0.001s
Tokens per second: 45904794.08
Processed 576/15020 cells
Batch processing time: 0.001s
Tokens per second: 46392895.69
Processed 640/15020 cells
Batch processing time: 0.001s
Tokens per second: 50270282.91
Processed 704/15020 cells
Batch processing time: 0.001s
Tokens per second: 51216304.63
Processed 768/15020 cells
Batch processing time: 0.001s
Tokens per second: 51302334.26
Processed 832/15020 cells
Batch processing time: 0.001s
Tokens per second: 52188704.57
Processed 896/15020 cells
Batch processing time: 0.001s
Tokens per second: 43756432.18
Processed 960/15020 cells
Batch processing time: 0.570s
Tokens per second: 114977.71
Processed 1024/15020 cells
Batch processing time: 0.587s
Tokens per second: 111619.79
Processed 1088/15020 cells
Batch processing time: 0.588s
Tokens per second: 111406.49
Processed 1152/15020 cells
Batch processing time: 0.584s
Tokens per second: 112215.35
Processed 1216/15020 cells
Batch processing time: 0.593s
Tokens per second: 110523.50
Processed 1280/15020 cells
Batch processing time: 0.596s
Tokens per second: 109958.60
Processed 1344/15020 cells
Batch processing time: 0.592s
Tokens per second: 110720.72
Processed 1408/15020 cells
Batch processing time: 0.593s
Tokens per second: 110537.10
Processed 1472/15020 cells
Batch processing time: 0.594s
Tokens per second: 110259.98
Processed 1536/15020 cells
Batch processing time: 0.598s
Tokens per second: 109617.66
Processed 1600/15020 cells
Batch processing time: 0.590s
Tokens per second: 111106.13
Processed 1664/15020 cells
Batch processing time: 0.596s
Tokens per second: 109929.88
Processed 1728/15020 cells
Batch processing time: 0.598s
Tokens per second: 109511.58
Processed 1792/15020 cells
Batch processing time: 0.600s
Tokens per second: 109300.74
Processed 1856/15020 cells
Batch processing time: 0.598s
Tokens per second: 109549.07
Processed 1920/15020 cells
Batch processing time: 0.592s
Tokens per second: 110771.54
Processed 1984/15020 cells
Batch processing time: 0.592s
Tokens per second: 110675.78
Processed 2048/15020 cells
Batch processing time: 0.601s
Tokens per second: 109117.85
Processed 2112/15020 cells
Batch processing time: 0.597s
Tokens per second: 109817.05
Processed 2176/15020 cells
Batch processing time: 0.601s
Tokens per second: 109126.21
Processed 2240/15020 cells
Batch processing time: 0.601s
Tokens per second: 108983.52
Processed 2304/15020 cells
Batch processing time: 0.602s
Tokens per second: 108800.49
Processed 2368/15020 cells
Batch processing time: 0.599s
Tokens per second: 109384.55
Processed 2432/15020 cells
Batch processing time: 0.599s
Tokens per second: 109354.79
Processed 2496/15020 cells
Batch processing time: 0.600s
Tokens per second: 109144.58
Processed 2560/15020 cells
Batch processing time: 0.602s
Tokens per second: 108872.67
Processed 2624/15020 cells
Batch processing time: 0.599s
Tokens per second: 109390.86
Processed 2688/15020 cells
Batch processing time: 0.601s
Tokens per second: 109105.07
Processed 2752/15020 cells
Batch processing time: 0.600s
Tokens per second: 109266.76
Processed 2816/15020 cells
Batch processing time: 0.600s
Tokens per second: 109188.81
Processed 2880/15020 cells
Batch processing time: 0.600s
Tokens per second: 109159.88
Processed 2944/15020 cells
Batch processing time: 0.602s
Tokens per second: 108915.55
Processed 3008/15020 cells
Batch processing time: 0.597s
Tokens per second: 109817.67
Processed 3072/15020 cells
Batch processing time: 0.597s
Tokens per second: 109757.90
Processed 3136/15020 cells
Batch processing time: 0.599s
Tokens per second: 109398.05
Processed 3200/15020 cells
Batch processing time: 0.605s
Tokens per second: 108409.88
Processed 3264/15020 cells
Batch processing time: 0.600s
Tokens per second: 109194.32
Processed 3328/15020 cells
Batch processing time: 0.599s
Tokens per second: 109374.63
Processed 3392/15020 cells
Batch processing time: 0.601s
Tokens per second: 109018.19
Processed 3456/15020 cells
Batch processing time: 0.599s
Tokens per second: 109431.45
Processed 3520/15020 cells
Batch processing time: 0.601s
Tokens per second: 109097.24
Processed 3584/15020 cells
Batch processing time: 0.600s
Tokens per second: 109189.11
Processed 3648/15020 cells
Batch processing time: 0.599s
Tokens per second: 109349.43
Processed 3712/15020 cells
Batch processing time: 0.600s
Tokens per second: 109238.62
Processed 3776/15020 cells
Batch processing time: 0.601s
Tokens per second: 109123.22
Processed 3840/15020 cells
Batch processing time: 0.599s
Tokens per second: 109392.08
Processed 3904/15020 cells
Batch processing time: 0.601s
Tokens per second: 109099.19
Processed 3968/15020 cells
Batch processing time: 0.600s
Tokens per second: 109292.87
Processed 4032/15020 cells
Batch processing time: 0.599s
Tokens per second: 109344.69
Processed 4096/15020 cells
Batch processing time: 0.601s
Tokens per second: 109103.78
Processed 4160/15020 cells
Batch processing time: 0.600s
Tokens per second: 109305.73
Processed 4224/15020 cells
Batch processing time: 0.601s
Tokens per second: 108988.88
Processed 4288/15020 cells
Batch processing time: 0.608s
Tokens per second: 107747.98
Processed 4352/15020 cells
Batch processing time: 0.611s
Tokens per second: 107300.71
Processed 4416/15020 cells
Batch processing time: 0.599s
Tokens per second: 109403.40
Processed 4480/15020 cells
Batch processing time: 0.617s
Tokens per second: 106278.31
Processed 4544/15020 cells
Batch processing time: 0.604s
Tokens per second: 108546.87
Processed 4608/15020 cells
Batch processing time: 0.612s
Tokens per second: 107150.97
Processed 4672/15020 cells
Batch processing time: 0.609s
Tokens per second: 107527.32
Processed 4736/15020 cells
Batch processing time: 0.610s
Tokens per second: 107457.80
Processed 4800/15020 cells
Batch processing time: 0.611s
Tokens per second: 107267.54
Processed 4864/15020 cells
Batch processing time: 0.609s
Tokens per second: 107577.57
Processed 4928/15020 cells
Batch processing time: 0.607s
Tokens per second: 107928.45
Processed 4992/15020 cells
Batch processing time: 0.610s
Tokens per second: 107365.38
Processed 5056/15020 cells
Batch processing time: 0.614s
Tokens per second: 106681.54
Processed 5120/15020 cells
Batch processing time: 0.614s
Tokens per second: 106760.39
Processed 5184/15020 cells
Batch processing time: 0.611s
Tokens per second: 107249.67
Processed 5248/15020 cells
Batch processing time: 0.615s
Tokens per second: 106490.56
Processed 5312/15020 cells
Batch processing time: 0.613s
Tokens per second: 106827.48
Processed 5376/15020 cells
Batch processing time: 0.614s
Tokens per second: 106748.58
Processed 5440/15020 cells
Batch processing time: 0.614s
Tokens per second: 106797.48
Processed 5504/15020 cells
Batch processing time: 0.617s
Tokens per second: 106239.45
Processed 5568/15020 cells
Batch processing time: 0.615s
Tokens per second: 106573.14
Processed 5632/15020 cells
Batch processing time: 0.604s
Tokens per second: 108510.96
Processed 5696/15020 cells
Batch processing time: 0.617s
Tokens per second: 106260.23
Processed 5760/15020 cells
Batch processing time: 0.614s
Tokens per second: 106665.90
Processed 5824/15020 cells
Batch processing time: 0.613s
Tokens per second: 106897.03
Processed 5888/15020 cells
Batch processing time: 0.617s
Tokens per second: 106215.15
Processed 5952/15020 cells
Batch processing time: 0.616s
Tokens per second: 106456.54
Processed 6016/15020 cells
Batch processing time: 0.617s
Tokens per second: 106167.11
Processed 6080/15020 cells
Batch processing time: 0.615s
Tokens per second: 106530.88
Processed 6144/15020 cells
Batch processing time: 0.614s
Tokens per second: 106764.21
Processed 6208/15020 cells
Batch processing time: 0.617s
Tokens per second: 106227.67
Processed 6272/15020 cells
Batch processing time: 0.617s
Tokens per second: 106185.94
Processed 6336/15020 cells
Batch processing time: 0.619s
Tokens per second: 105932.18
Processed 6400/15020 cells
Batch processing time: 0.618s
Tokens per second: 105967.06
Processed 6464/15020 cells
Batch processing time: 0.619s
Tokens per second: 105900.88
Processed 6528/15020 cells
Batch processing time: 0.609s
Tokens per second: 107607.22
Processed 6592/15020 cells
Batch processing time: 0.619s
Tokens per second: 105884.32
Processed 6656/15020 cells
Batch processing time: 0.624s
Tokens per second: 105079.03
Processed 6720/15020 cells
Batch processing time: 0.623s
Tokens per second: 105255.75
Processed 6784/15020 cells
Batch processing time: 0.616s
Tokens per second: 106333.16
Processed 6848/15020 cells
Batch processing time: 0.619s
Tokens per second: 105832.54
Processed 6912/15020 cells
Batch processing time: 0.619s
Tokens per second: 105944.23
Processed 6976/15020 cells
Batch processing time: 0.617s
Tokens per second: 106261.96
Processed 7040/15020 cells
Batch processing time: 0.624s
Tokens per second: 105102.65
Processed 7104/15020 cells
Batch processing time: 0.627s
Tokens per second: 104583.48
Processed 7168/15020 cells
Batch processing time: 0.622s
Tokens per second: 105433.06
Processed 7232/15020 cells
Batch processing time: 0.618s
Tokens per second: 106097.65
Processed 7296/15020 cells
Batch processing time: 0.619s
Tokens per second: 105857.65
Processed 7360/15020 cells
Batch processing time: 0.618s
Tokens per second: 106053.32
Processed 7424/15020 cells
Batch processing time: 0.614s
Tokens per second: 106793.37
Processed 7488/15020 cells
Batch processing time: 0.630s
Tokens per second: 104103.98
Processed 7552/15020 cells
Batch processing time: 0.621s
Tokens per second: 105540.74
Processed 7616/15020 cells
Batch processing time: 0.621s
Tokens per second: 105493.15
Processed 7680/15020 cells
Batch processing time: 0.622s
Tokens per second: 105364.11
Processed 7744/15020 cells
Batch processing time: 0.622s
Tokens per second: 105288.73
Processed 7808/15020 cells
Batch processing time: 0.624s
Tokens per second: 105054.73
Processed 7872/15020 cells
Batch processing time: 0.621s
Tokens per second: 105474.57
Processed 7936/15020 cells
Batch processing time: 0.620s
Tokens per second: 105757.29
Processed 8000/15020 cells
Batch processing time: 0.618s
Tokens per second: 106105.39
Processed 8064/15020 cells
Batch processing time: 0.625s
Tokens per second: 104777.38
Processed 8128/15020 cells
Batch processing time: 0.619s
Tokens per second: 105852.43
Processed 8192/15020 cells
Batch processing time: 0.624s
Tokens per second: 104951.88
Processed 8256/15020 cells
Batch processing time: 0.628s
Tokens per second: 104425.67
Processed 8320/15020 cells
Batch processing time: 0.624s
Tokens per second: 104979.34
Processed 8384/15020 cells
Batch processing time: 0.621s
Tokens per second: 105611.95
Processed 8448/15020 cells
Batch processing time: 0.621s
Tokens per second: 105496.75
Processed 8512/15020 cells
Batch processing time: 0.624s
Tokens per second: 105097.71
Processed 8576/15020 cells
Batch processing time: 0.614s
Tokens per second: 106670.45
Processed 8640/15020 cells
Batch processing time: 0.627s
Tokens per second: 104529.11
Processed 8704/15020 cells
Batch processing time: 0.622s
Tokens per second: 105323.62
Processed 8768/15020 cells
Batch processing time: 0.622s
Tokens per second: 105308.13
Processed 8832/15020 cells
Batch processing time: 0.632s
Tokens per second: 103765.96
Processed 8896/15020 cells
Batch processing time: 0.627s
Tokens per second: 104513.37
Processed 8960/15020 cells
Batch processing time: 0.627s
Tokens per second: 104531.38
Processed 9024/15020 cells
Batch processing time: 0.626s
Tokens per second: 104756.42
Processed 9088/15020 cells
Batch processing time: 0.629s
Tokens per second: 104118.29
Processed 9152/15020 cells
Batch processing time: 0.627s
Tokens per second: 104581.05
Processed 9216/15020 cells
Batch processing time: 0.625s
Tokens per second: 104810.94
Processed 9280/15020 cells
Batch processing time: 0.628s
Tokens per second: 104365.40
Processed 9344/15020 cells
Batch processing time: 0.626s
Tokens per second: 104657.86
Processed 9408/15020 cells
Batch processing time: 0.625s
Tokens per second: 104877.76
Processed 9472/15020 cells
Batch processing time: 0.629s
Tokens per second: 104145.43
Processed 9536/15020 cells
Batch processing time: 0.626s
Tokens per second: 104731.63
Processed 9600/15020 cells
Batch processing time: 0.626s
Tokens per second: 104747.64
Processed 9664/15020 cells
Batch processing time: 0.624s
Tokens per second: 105033.05
Processed 9728/15020 cells
Batch processing time: 0.627s
Tokens per second: 104556.71
Processed 9792/15020 cells
Batch processing time: 0.627s
Tokens per second: 104457.17
Processed 9856/15020 cells
Batch processing time: 0.626s
Tokens per second: 104705.54
Processed 9920/15020 cells
Batch processing time: 0.629s
Tokens per second: 104207.42
Processed 9984/15020 cells
Batch processing time: 0.626s
Tokens per second: 104716.67
Processed 10048/15020 cells
Batch processing time: 0.629s
Tokens per second: 104121.44
Processed 10112/15020 cells
Batch processing time: 0.626s
Tokens per second: 104770.79
Processed 10176/15020 cells
Batch processing time: 0.628s
Tokens per second: 104369.56
Processed 10240/15020 cells
Batch processing time: 0.630s
Tokens per second: 104040.89
Processed 10304/15020 cells
Batch processing time: 0.628s
Tokens per second: 104383.95
Processed 10368/15020 cells
Batch processing time: 0.631s
Tokens per second: 103804.29
Processed 10432/15020 cells
Batch processing time: 0.625s
Tokens per second: 104878.20
Processed 10496/15020 cells
Batch processing time: 0.629s
Tokens per second: 104121.72
Processed 10560/15020 cells
Batch processing time: 0.630s
Tokens per second: 104055.86
Processed 10624/15020 cells
Batch processing time: 0.628s
Tokens per second: 104284.67
Processed 10688/15020 cells
Batch processing time: 0.631s
Tokens per second: 103841.23
Processed 10752/15020 cells
Batch processing time: 0.628s
Tokens per second: 104418.68
Processed 10816/15020 cells
Batch processing time: 0.631s
Tokens per second: 103789.39
Processed 10880/15020 cells
Batch processing time: 0.627s
Tokens per second: 104466.31
Processed 10944/15020 cells
Batch processing time: 0.635s
Tokens per second: 103242.82
Processed 11008/15020 cells
Batch processing time: 0.628s
Tokens per second: 104349.83
Processed 11072/15020 cells
Batch processing time: 0.633s
Tokens per second: 103488.78
Processed 11136/15020 cells
Batch processing time: 0.630s
Tokens per second: 103996.29
Processed 11200/15020 cells
Batch processing time: 0.628s
Tokens per second: 104371.03
Processed 11264/15020 cells
Batch processing time: 0.631s
Tokens per second: 103838.40
Processed 11328/15020 cells
Batch processing time: 0.629s
Tokens per second: 104224.96
Processed 11392/15020 cells
Batch processing time: 0.631s
Tokens per second: 103868.50
Processed 11456/15020 cells
Batch processing time: 0.631s
Tokens per second: 103903.83
Processed 11520/15020 cells
Batch processing time: 0.633s
Tokens per second: 103597.45
Processed 11584/15020 cells
Batch processing time: 0.628s
Tokens per second: 104347.57
Processed 11648/15020 cells
Batch processing time: 0.634s
Tokens per second: 103296.51
Processed 11712/15020 cells
Batch processing time: 0.630s
Tokens per second: 104014.28
Processed 11776/15020 cells
Batch processing time: 0.634s
Tokens per second: 103424.42
Processed 11840/15020 cells
Batch processing time: 0.631s
Tokens per second: 103810.56
Processed 11904/15020 cells
Batch processing time: 0.631s
Tokens per second: 103904.74
Processed 11968/15020 cells
Batch processing time: 0.633s
Tokens per second: 103575.55
Processed 12032/15020 cells
Batch processing time: 0.631s
Tokens per second: 103866.81
Processed 12096/15020 cells
Batch processing time: 0.632s
Tokens per second: 103668.17
Processed 12160/15020 cells
Batch processing time: 0.633s
Tokens per second: 103480.02
Processed 12224/15020 cells
Batch processing time: 0.631s
Tokens per second: 103861.67
Processed 12288/15020 cells
Batch processing time: 0.637s
Tokens per second: 102920.07
Processed 12352/15020 cells
Batch processing time: 0.633s
Tokens per second: 103515.36
Processed 12416/15020 cells
Batch processing time: 0.632s
Tokens per second: 103695.54
Processed 12480/15020 cells
Batch processing time: 0.633s
Tokens per second: 103566.30
Processed 12544/15020 cells
Batch processing time: 0.631s
Tokens per second: 103790.73
Processed 12608/15020 cells
Batch processing time: 0.630s
Tokens per second: 103977.02
Processed 12672/15020 cells
Batch processing time: 0.635s
Tokens per second: 103135.90
Processed 12736/15020 cells
Batch processing time: 0.632s
Tokens per second: 103699.57
Processed 12800/15020 cells
Batch processing time: 0.630s
Tokens per second: 103971.28
Processed 12864/15020 cells
Batch processing time: 0.633s
Tokens per second: 103507.80
Processed 12928/15020 cells
Batch processing time: 0.632s
Tokens per second: 103767.14
Processed 12992/15020 cells
Batch processing time: 0.635s
Tokens per second: 103266.79
Processed 13056/15020 cells
Batch processing time: 0.636s
Tokens per second: 103090.80
Processed 13120/15020 cells
Batch processing time: 0.633s
Tokens per second: 103570.59
Processed 13184/15020 cells
Batch processing time: 0.632s
Tokens per second: 103637.52
Processed 13248/15020 cells
Batch processing time: 0.634s
Tokens per second: 103304.78
Processed 13312/15020 cells
Batch processing time: 0.635s
Tokens per second: 103193.09
Processed 13376/15020 cells
Batch processing time: 0.632s
Tokens per second: 103725.52
Processed 13440/15020 cells
Batch processing time: 0.635s
Tokens per second: 103125.53
Processed 13504/15020 cells
Batch processing time: 0.634s
Tokens per second: 103326.68
Processed 13568/15020 cells
Batch processing time: 0.633s
Tokens per second: 103495.45
Processed 13632/15020 cells
Batch processing time: 0.637s
Tokens per second: 102921.85
Processed 13696/15020 cells
Batch processing time: 0.635s
Tokens per second: 103135.59
Processed 13760/15020 cells
Batch processing time: 0.636s
Tokens per second: 102979.15
Processed 13824/15020 cells
Batch processing time: 0.632s
Tokens per second: 103705.71
Processed 13888/15020 cells
Batch processing time: 0.633s
Tokens per second: 103576.13
Processed 13952/15020 cells
Batch processing time: 0.634s
Tokens per second: 103340.01
Processed 14016/15020 cells
Batch processing time: 0.635s
Tokens per second: 103219.17
Processed 14080/15020 cells
Batch processing time: 0.634s
Tokens per second: 103321.01
Processed 14144/15020 cells
Batch processing time: 0.636s
Tokens per second: 103123.25
Processed 14208/15020 cells
Batch processing time: 0.636s
Tokens per second: 103077.19
Processed 14272/15020 cells
Batch processing time: 0.633s
Tokens per second: 103497.47
Processed 14336/15020 cells
Batch processing time: 0.635s
Tokens per second: 103246.58
Processed 14400/15020 cells
Batch processing time: 0.634s
Tokens per second: 103368.61
Processed 14464/15020 cells
Batch processing time: 0.635s
Tokens per second: 103154.29
Processed 14528/15020 cells
Batch processing time: 0.632s
Tokens per second: 103643.42
Processed 14592/15020 cells
Batch processing time: 0.634s
Tokens per second: 103336.74
Processed 14656/15020 cells
Batch processing time: 0.635s
Tokens per second: 103256.35
Processed 14720/15020 cells
Batch processing time: 0.635s
Tokens per second: 103244.41
Processed 14784/15020 cells
Batch processing time: 0.633s
Tokens per second: 103544.88
Processed 14848/15020 cells
Batch processing time: 0.635s
Tokens per second: 103153.24
Processed 14912/15020 cells
Batch processing time: 0.637s
Tokens per second: 102921.39
Processed 14976/15020 cells
Batch processing time: 0.634s
Tokens per second: 71092.39
Final embeddings shape: torch.Size([15020, 1280])
Total processing time: 136.83s
Average tokens per second: 112407.93
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
src.shape torch.Size([1024, 128, 1280])
embedding.shape torch.Size([128, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 183, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 161, in sample_from_model
    cell_emb = model(batch)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 86, in forward
    prob_ex = self.binary_decoder(torch.cat((embedding.expand(batch_size, -1), src[1:, :, :])))
RuntimeError: Tensors must have same number of dimensions: got 2 and 3
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([128, 1280])
Processed 0/15020 cells
Batch processing time: 1.320s
Tokens per second: 99289.03
torch.Size([128, 1280])
Processed 128/15020 cells
Batch processing time: 0.002s
Tokens per second: 61480184.96
torch.Size([128, 1280])
Processed 256/15020 cells
Batch processing time: 0.002s
Tokens per second: 76493086.67
torch.Size([128, 1280])
Processed 384/15020 cells
Batch processing time: 0.001s
Tokens per second: 98170681.05
torch.Size([128, 1280])
Processed 512/15020 cells
Batch processing time: 0.001s
Tokens per second: 87610488.27
torch.Size([128, 1280])
Processed 640/15020 cells
Batch processing time: 0.001s
Tokens per second: 99019418.93
torch.Size([128, 1280])
Processed 768/15020 cells
Batch processing time: 0.001s
Tokens per second: 103805856.10
torch.Size([128, 1280])
Processed 896/15020 cells
Batch processing time: 0.002s
Tokens per second: 86398839.21
torch.Size([128, 1280])
Processed 1024/15020 cells
Batch processing time: 0.001s
Tokens per second: 91886313.54
torch.Size([128, 1280])
Processed 1152/15020 cells
Batch processing time: 0.001s
Tokens per second: 101618449.89
torch.Size([128, 1280])
Processed 1280/15020 cells
Batch processing time: 0.002s
Tokens per second: 87014215.56
torch.Size([128, 1280])
Processed 1408/15020 cells
Batch processing time: 0.001s
Tokens per second: 98275976.74
torch.Size([128, 1280])
Processed 1536/15020 cells
Batch processing time: 0.001s
Tokens per second: 96380752.79
torch.Size([128, 1280])
Processed 1664/15020 cells
Batch processing time: 0.065s
Tokens per second: 2024659.57
torch.Size([128, 1280])
Processed 1792/15020 cells
Batch processing time: 1.189s
Tokens per second: 110196.02
torch.Size([128, 1280])
Processed 1920/15020 cells
Batch processing time: 1.177s
Tokens per second: 111345.72
torch.Size([128, 1280])
Processed 2048/15020 cells
Batch processing time: 1.182s
Tokens per second: 110852.06
torch.Size([128, 1280])
Processed 2176/15020 cells
Batch processing time: 1.185s
Tokens per second: 110599.90
torch.Size([128, 1280])
Processed 2304/15020 cells
Batch processing time: 1.185s
Tokens per second: 110645.93
torch.Size([128, 1280])
Processed 2432/15020 cells
Batch processing time: 1.186s
Tokens per second: 110511.28
torch.Size([128, 1280])
Processed 2560/15020 cells
Batch processing time: 1.186s
Tokens per second: 110558.97
torch.Size([128, 1280])
Processed 2688/15020 cells
Batch processing time: 1.191s
Tokens per second: 110035.82
torch.Size([128, 1280])
Processed 2816/15020 cells
Batch processing time: 1.195s
Tokens per second: 109718.21
torch.Size([128, 1280])
Processed 2944/15020 cells
Batch processing time: 1.189s
Tokens per second: 110266.88
torch.Size([128, 1280])
Processed 3072/15020 cells
Batch processing time: 1.199s
Tokens per second: 109313.88
torch.Size([128, 1280])
Processed 3200/15020 cells
Batch processing time: 1.200s
Tokens per second: 109229.09
torch.Size([128, 1280])
Processed 3328/15020 cells
Batch processing time: 1.201s
Tokens per second: 109166.93
torch.Size([128, 1280])
Processed 3456/15020 cells
Batch processing time: 1.201s
Tokens per second: 109098.12
torch.Size([128, 1280])
Processed 3584/15020 cells
Batch processing time: 1.216s
Tokens per second: 107751.16
torch.Size([128, 1280])
Processed 3712/15020 cells
Batch processing time: 1.194s
Tokens per second: 109761.63
torch.Size([128, 1280])
Processed 3840/15020 cells
Batch processing time: 1.195s
Tokens per second: 109727.01
torch.Size([128, 1280])
Processed 3968/15020 cells
Batch processing time: 1.207s
Tokens per second: 108623.50
torch.Size([128, 1280])
Processed 4096/15020 cells
Batch processing time: 1.202s
Tokens per second: 109082.32
torch.Size([128, 1280])
Processed 4224/15020 cells
Batch processing time: 1.217s
Tokens per second: 107689.91
torch.Size([128, 1280])
Processed 4352/15020 cells
Batch processing time: 1.214s
Tokens per second: 107972.80
torch.Size([128, 1280])
Processed 4480/15020 cells
Batch processing time: 1.203s
Tokens per second: 108961.01
torch.Size([128, 1280])
Processed 4608/15020 cells
Batch processing time: 1.218s
Tokens per second: 107640.53
torch.Size([128, 1280])
Processed 4736/15020 cells
Batch processing time: 1.222s
Tokens per second: 107271.81
torch.Size([128, 1280])
Processed 4864/15020 cells
Batch processing time: 1.219s
Tokens per second: 107527.41
torch.Size([128, 1280])
Processed 4992/15020 cells
Batch processing time: 1.219s
Tokens per second: 107544.34
torch.Size([128, 1280])
Processed 5120/15020 cells
Batch processing time: 1.220s
Tokens per second: 107474.81
torch.Size([128, 1280])
Processed 5248/15020 cells
Batch processing time: 1.221s
Tokens per second: 107351.48
torch.Size([128, 1280])
Processed 5376/15020 cells
Batch processing time: 1.220s
Tokens per second: 107404.96
torch.Size([128, 1280])
Processed 5504/15020 cells
Batch processing time: 1.220s
Tokens per second: 107451.14
torch.Size([128, 1280])
Processed 5632/15020 cells
Batch processing time: 1.221s
Tokens per second: 107374.58
torch.Size([128, 1280])
Processed 5760/15020 cells
Batch processing time: 1.220s
Tokens per second: 107459.33
torch.Size([128, 1280])
Processed 5888/15020 cells
Batch processing time: 1.223s
Tokens per second: 107213.93
torch.Size([128, 1280])
Processed 6016/15020 cells
Batch processing time: 1.217s
Tokens per second: 107674.54
torch.Size([128, 1280])
Processed 6144/15020 cells
Batch processing time: 1.216s
Tokens per second: 107828.68
torch.Size([128, 1280])
Processed 6272/15020 cells
Batch processing time: 1.208s
Tokens per second: 108521.78
torch.Size([128, 1280])
Processed 6400/15020 cells
Batch processing time: 1.230s
Tokens per second: 106586.55
torch.Size([128, 1280])
Processed 6528/15020 cells
Batch processing time: 1.202s
Tokens per second: 109040.33
torch.Size([128, 1280])
Processed 6656/15020 cells
Batch processing time: 1.221s
Tokens per second: 107334.54
torch.Size([128, 1280])
Processed 6784/15020 cells
Batch processing time: 1.237s
Tokens per second: 105977.15
torch.Size([128, 1280])
Processed 6912/15020 cells
Batch processing time: 1.225s
Tokens per second: 107012.18
torch.Size([128, 1280])
Processed 7040/15020 cells
Batch processing time: 1.214s
Tokens per second: 107926.23
torch.Size([128, 1280])
Processed 7168/15020 cells
Batch processing time: 1.229s
Tokens per second: 106683.22
torch.Size([128, 1280])
Processed 7296/15020 cells
Batch processing time: 1.235s
Tokens per second: 106133.17
torch.Size([128, 1280])
Processed 7424/15020 cells
Batch processing time: 1.230s
Tokens per second: 106532.82
torch.Size([128, 1280])
Processed 7552/15020 cells
Batch processing time: 1.208s
Tokens per second: 108498.09
torch.Size([128, 1280])
Processed 7680/15020 cells
Batch processing time: 1.240s
Tokens per second: 105661.03
torch.Size([128, 1280])
Processed 7808/15020 cells
Batch processing time: 1.242s
Tokens per second: 105540.15
torch.Size([128, 1280])
Processed 7936/15020 cells
Batch processing time: 1.237s
Tokens per second: 105927.45
torch.Size([128, 1280])
Processed 8064/15020 cells
Batch processing time: 1.236s
Tokens per second: 106037.69
torch.Size([128, 1280])
Processed 8192/15020 cells
Batch processing time: 1.239s
Tokens per second: 105772.41
torch.Size([128, 1280])
Processed 8320/15020 cells
Batch processing time: 1.222s
Tokens per second: 107257.87
torch.Size([128, 1280])
Processed 8448/15020 cells
Batch processing time: 1.239s
Tokens per second: 105788.78
torch.Size([128, 1280])
Processed 8576/15020 cells
Batch processing time: 1.236s
Tokens per second: 106087.62
torch.Size([128, 1280])
Processed 8704/15020 cells
Batch processing time: 1.230s
Tokens per second: 106578.36
torch.Size([128, 1280])
Processed 8832/15020 cells
Batch processing time: 1.242s
Tokens per second: 105502.75
torch.Size([128, 1280])
Processed 8960/15020 cells
Batch processing time: 1.232s
Tokens per second: 106385.94
torch.Size([128, 1280])
Processed 9088/15020 cells
Batch processing time: 1.238s
Tokens per second: 105856.75
torch.Size([128, 1280])
Processed 9216/15020 cells
Batch processing time: 1.246s
Tokens per second: 105203.46
torch.Size([128, 1280])
Processed 9344/15020 cells
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([64, 1280])
Processed 0/15020 cells
Batch processing time: 0.716s
Tokens per second: 91539.92
torch.Size([64, 1280])
Processed 64/15020 cells
Batch processing time: 0.002s
Tokens per second: 32982710.22
torch.Size([64, 1280])
Processed 128/15020 cells
Batch processing time: 0.001s
Tokens per second: 52010956.85
torch.Size([64, 1280])
Processed 192/15020 cells
Batch processing time: 0.002s
Tokens per second: 42942963.12
torch.Size([64, 1280])
Processed 256/15020 cells
Batch processing time: 0.001s
Tokens per second: 53992910.42
torch.Size([64, 1280])
Processed 320/15020 cells
Batch processing time: 0.001s
Tokens per second: 52427600.03
torch.Size([64, 1280])
Processed 384/15020 cells
Batch processing time: 0.001s
Tokens per second: 53697579.01
torch.Size([64, 1280])
Processed 448/15020 cells
Batch processing time: 0.001s
Tokens per second: 53603335.99
torch.Size([64, 1280])
Processed 512/15020 cells
Batch processing time: 0.001s
Tokens per second: 54152463.94
torch.Size([64, 1280])
Processed 576/15020 cells
Batch processing time: 0.001s
Tokens per second: 46455620.58
torch.Size([64, 1280])
Processed 640/15020 cells
Batch processing time: 0.001s
Tokens per second: 53897628.81
torch.Size([64, 1280])
Processed 704/15020 cells
Batch processing time: 0.001s
Tokens per second: 52578023.52
torch.Size([64, 1280])
Processed 768/15020 cells
Batch processing time: 0.001s
Tokens per second: 54163134.37
torch.Size([64, 1280])
Processed 832/15020 cells
Batch processing time: 0.001s
Tokens per second: 54377429.66
torch.Size([64, 1280])
Processed 896/15020 cells
Batch processing time: 0.001s
Tokens per second: 54280787.31
torch.Size([64, 1280])
Processed 960/15020 cells
Batch processing time: 0.578s
Tokens per second: 113331.85
torch.Size([64, 1280])
Processed 1024/15020 cells
Batch processing time: 0.590s
Tokens per second: 111073.13
torch.Size([64, 1280])
Processed 1088/15020 cells
Batch processing time: 0.593s
Tokens per second: 110602.21
torch.Size([64, 1280])
Processed 1152/15020 cells
Batch processing time: 0.592s
Tokens per second: 110758.91
torch.Size([64, 1280])
Processed 1216/15020 cells
Batch processing time: 0.606s
Tokens per second: 108196.48
torch.Size([64, 1280])
Processed 1280/15020 cells
Batch processing time: 0.596s
Tokens per second: 109933.53
torch.Size([64, 1280])
Processed 1344/15020 cells
Batch processing time: 0.604s
Tokens per second: 108515.85
torch.Size([64, 1280])
Processed 1408/15020 cells
Batch processing time: 0.599s
Tokens per second: 109431.15
torch.Size([64, 1280])
Processed 1472/15020 cells
Batch processing time: 0.600s
Tokens per second: 109176.23
torch.Size([64, 1280])
Processed 1536/15020 cells
Batch processing time: 0.601s
Tokens per second: 109119.93
torch.Size([64, 1280])
Processed 1600/15020 cells
Batch processing time: 0.600s
Tokens per second: 109253.30
torch.Size([64, 1280])
Processed 1664/15020 cells
Batch processing time: 0.601s
Tokens per second: 109128.81
torch.Size([64, 1280])
Processed 1728/15020 cells
Batch processing time: 0.597s
Tokens per second: 109770.00
torch.Size([64, 1280])
Processed 1792/15020 cells
Batch processing time: 0.602s
Tokens per second: 108837.84
torch.Size([64, 1280])
Processed 1856/15020 cells
Batch processing time: 0.600s
Tokens per second: 109267.76
torch.Size([64, 1280])
Processed 1920/15020 cells
Batch processing time: 0.601s
Tokens per second: 109023.81
torch.Size([64, 1280])
Processed 1984/15020 cells
Batch processing time: 0.597s
Tokens per second: 109763.77
torch.Size([64, 1280])
Processed 2048/15020 cells
Batch processing time: 0.602s
Tokens per second: 108779.09
torch.Size([64, 1280])
Processed 2112/15020 cells
Batch processing time: 0.598s
Tokens per second: 109510.14
torch.Size([64, 1280])
Processed 2176/15020 cells
Batch processing time: 0.601s
Tokens per second: 109106.46
torch.Size([64, 1280])
Processed 2240/15020 cells
Batch processing time: 0.601s
Tokens per second: 109034.75
torch.Size([64, 1280])
Processed 2304/15020 cells
Batch processing time: 0.599s
Tokens per second: 109392.39
torch.Size([64, 1280])
Processed 2368/15020 cells
Batch processing time: 0.601s
Tokens per second: 108992.29
torch.Size([64, 1280])
Processed 2432/15020 cells
Batch processing time: 0.602s
Tokens per second: 108858.66
torch.Size([64, 1280])
Processed 2496/15020 cells
Batch processing time: 0.607s
Tokens per second: 108032.59
torch.Size([64, 1280])
Processed 2560/15020 cells
Batch processing time: 0.610s
Tokens per second: 107351.54
torch.Size([64, 1280])
Processed 2624/15020 cells
Batch processing time: 0.603s
Tokens per second: 108611.72
torch.Size([64, 1280])
Processed 2688/15020 cells
Batch processing time: 0.609s
Tokens per second: 107607.98
torch.Size([64, 1280])
Processed 2752/15020 cells
Batch processing time: 0.606s
Tokens per second: 108067.93
torch.Size([64, 1280])
Processed 2816/15020 cells
Batch processing time: 0.601s
Tokens per second: 109002.71
torch.Size([64, 1280])
Processed 2880/15020 cells
Batch processing time: 0.613s
Tokens per second: 106877.20
torch.Size([64, 1280])
Processed 2944/15020 cells
Batch processing time: 0.606s
Tokens per second: 108068.99
torch.Size([64, 1280])
Processed 3008/15020 cells
Batch processing time: 0.611s
Tokens per second: 107237.58
torch.Size([64, 1280])
Processed 3072/15020 cells
Batch processing time: 0.610s
Tokens per second: 107375.23
torch.Size([64, 1280])
Processed 3136/15020 cells
Batch processing time: 0.609s
Tokens per second: 107582.37
torch.Size([64, 1280])
Processed 3200/15020 cells
Batch processing time: 0.609s
Tokens per second: 107672.00
torch.Size([64, 1280])
Processed 3264/15020 cells
Batch processing time: 0.610s
Tokens per second: 107418.79
torch.Size([64, 1280])
Processed 3328/15020 cells
Batch processing time: 0.610s
Tokens per second: 107507.56
torch.Size([64, 1280])
Processed 3392/15020 cells
Batch processing time: 0.610s
Tokens per second: 107363.49
torch.Size([64, 1280])
Processed 3456/15020 cells
Batch processing time: 0.609s
Tokens per second: 107638.40
torch.Size([64, 1280])
Processed 3520/15020 cells
Batch processing time: 0.611s
Tokens per second: 107280.02
torch.Size([64, 1280])
Processed 3584/15020 cells
Batch processing time: 0.610s
Tokens per second: 107381.44
torch.Size([64, 1280])
Processed 3648/15020 cells
Batch processing time: 0.613s
Tokens per second: 106848.62
torch.Size([64, 1280])
Processed 3712/15020 cells
Batch processing time: 0.609s
Tokens per second: 107573.23
torch.Size([64, 1280])
Processed 3776/15020 cells
Batch processing time: 0.614s
Tokens per second: 106679.14
torch.Size([64, 1280])
Processed 3840/15020 cells
Batch processing time: 0.613s
Tokens per second: 106829.27
torch.Size([64, 1280])
Processed 3904/15020 cells
Batch processing time: 0.612s
Tokens per second: 107075.79
torch.Size([64, 1280])
Processed 3968/15020 cells
Batch processing time: 0.615s
Tokens per second: 106604.92
torch.Size([64, 1280])
Processed 4032/15020 cells
Batch processing time: 0.613s
Tokens per second: 106866.23
torch.Size([64, 1280])
Processed 4096/15020 cells
Batch processing time: 0.620s
Tokens per second: 105673.99
torch.Size([64, 1280])
Processed 4160/15020 cells
Batch processing time: 0.607s
Tokens per second: 107937.78
torch.Size([64, 1280])
Processed 4224/15020 cells
Batch processing time: 0.618s
Tokens per second: 106079.02
torch.Size([64, 1280])
Processed 4288/15020 cells
Batch processing time: 0.613s
Tokens per second: 106907.71
torch.Size([64, 1280])
Processed 4352/15020 cells
Batch processing time: 0.614s
Tokens per second: 106752.31
torch.Size([64, 1280])
Processed 4416/15020 cells
Batch processing time: 0.615s
Tokens per second: 106569.66
torch.Size([64, 1280])
Processed 4480/15020 cells
Batch processing time: 0.618s
Tokens per second: 106072.43
torch.Size([64, 1280])
Processed 4544/15020 cells
Batch processing time: 0.618s
Tokens per second: 106019.17
torch.Size([64, 1280])
Processed 4608/15020 cells
Batch processing time: 0.615s
Tokens per second: 106634.32
torch.Size([64, 1280])
Processed 4672/15020 cells
Batch processing time: 0.615s
Tokens per second: 106579.58
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 89, in <module>
    model = TransformerModel(
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 54, in __init__
    self.decoder = nn.Sequential(full_block(d_model, j))
NameError: name 'j' is not defined
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 0/15020 cells
Batch processing time: 0.730s
Tokens per second: 89803.23
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 64/15020 cells
Batch processing time: 0.002s
Tokens per second: 33818640.13
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 128/15020 cells
Batch processing time: 0.001s
Tokens per second: 49724657.55
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 192/15020 cells
Batch processing time: 0.002s
Tokens per second: 38455219.21
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 256/15020 cells
Batch processing time: 0.001s
Tokens per second: 50659400.47
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 320/15020 cells
Batch processing time: 0.001s
Tokens per second: 53939934.64
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 384/15020 cells
Batch processing time: 0.001s
Tokens per second: 53446997.27
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 448/15020 cells
Batch processing time: 0.001s
Tokens per second: 52198615.07
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 512/15020 cells
Batch processing time: 0.001s
Tokens per second: 48411043.84
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 576/15020 cells
Batch processing time: 0.002s
Tokens per second: 40536485.32
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 640/15020 cells
Batch processing time: 0.001s
Tokens per second: 50931611.44
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 704/15020 cells
Batch processing time: 0.001s
Tokens per second: 53676607.49
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 768/15020 cells
Batch processing time: 0.001s
Tokens per second: 52628356.68
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 832/15020 cells
Batch processing time: 0.001s
Tokens per second: 52317835.35
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 896/15020 cells
Batch processing time: 0.121s
Tokens per second: 540926.81
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 960/15020 cells
Batch processing time: 0.608s
Tokens per second: 107812.47
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1024/15020 cells
Batch processing time: 0.591s
Tokens per second: 110813.11
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1088/15020 cells
Batch processing time: 0.604s
Tokens per second: 108591.30
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1152/15020 cells
Batch processing time: 0.599s
Tokens per second: 109494.31
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1216/15020 cells
Batch processing time: 0.602s
Tokens per second: 108878.79
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1280/15020 cells
Batch processing time: 0.601s
Tokens per second: 108994.45
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1344/15020 cells
Batch processing time: 0.602s
Tokens per second: 108869.65
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1408/15020 cells
Batch processing time: 0.601s
Tokens per second: 109113.00
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1472/15020 cells
Batch processing time: 0.599s
Tokens per second: 109440.03
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1536/15020 cells
Batch processing time: 0.601s
Tokens per second: 109032.28
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1600/15020 cells
Batch processing time: 0.600s
Tokens per second: 109277.97
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1664/15020 cells
Batch processing time: 0.601s
Tokens per second: 109115.90
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1728/15020 cells
Batch processing time: 0.597s
Tokens per second: 109783.50
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1792/15020 cells
Batch processing time: 0.603s
Tokens per second: 108764.11
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1856/15020 cells
Batch processing time: 0.599s
Tokens per second: 109406.71
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1920/15020 cells
Batch processing time: 0.601s
Tokens per second: 109009.45
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 1984/15020 cells
Batch processing time: 0.600s
Tokens per second: 109264.94
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2048/15020 cells
Batch processing time: 0.599s
Tokens per second: 109329.56
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2112/15020 cells
Batch processing time: 0.600s
Tokens per second: 109212.49
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2176/15020 cells
Batch processing time: 0.599s
Tokens per second: 109338.47
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2240/15020 cells
Batch processing time: 0.601s
Tokens per second: 109134.79
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2304/15020 cells
Batch processing time: 0.600s
Tokens per second: 109285.18
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2368/15020 cells
Batch processing time: 0.600s
Tokens per second: 109180.31
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2432/15020 cells
Batch processing time: 0.600s
Tokens per second: 109179.74
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2496/15020 cells
Batch processing time: 0.599s
Tokens per second: 109412.50
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2560/15020 cells
Batch processing time: 0.604s
Tokens per second: 108495.11
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2624/15020 cells
Batch processing time: 0.611s
Tokens per second: 107328.48
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2688/15020 cells
Batch processing time: 0.607s
Tokens per second: 107979.20
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2752/15020 cells
Batch processing time: 0.598s
Tokens per second: 109532.62
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2816/15020 cells
Batch processing time: 0.601s
Tokens per second: 109038.60
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2880/15020 cells
Batch processing time: 0.599s
Tokens per second: 109430.88
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 2944/15020 cells
Batch processing time: 0.601s
Tokens per second: 109016.80
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 3008/15020 cells
Batch processing time: 0.601s
Tokens per second: 108999.68
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 3072/15020 cells
Batch processing time: 0.613s
Tokens per second: 106857.93
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 3136/15020 cells
Batch processing time: 0.605s
Tokens per second: 108296.99
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 3200/15020 cells
Batch processing time: 0.600s
Tokens per second: 109227.94
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 3264/15020 cells
Batch processing time: 0.612s
Tokens per second: 106999.68
batch_counts.shape torch.Size([64, 19565])
torch.Size([64, 1280])
Processed 3328/15020 cells
Batch processing time: 0.606s
Tokens per second: 108102.01
batch_counts.shape torch.Size([64, 19565])
Using device: cuda
Total parameters: 444,834,925
Trainable parameters: 344,662,125
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 189, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 167, in sample_from_model
    cell_emb = model(batch, batch_counts)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 86, in forward
    msa_loss = torch.nn.MSALoss()
AttributeError: module 'torch.nn' has no attribute 'MSALoss'. Did you mean: 'MSELoss'?
Using device: cuda
Total parameters: 444,834,925
Trainable parameters: 344,662,125
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 189, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 167, in sample_from_model
    cell_emb = model(batch, batch_counts)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 92, in forward
    loss.backward()
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Using device: cuda
Total parameters: 444,834,925
Trainable parameters: 344,662,125
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 189, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 167, in sample_from_model
    cell_emb = model(batch, batch_counts)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 92, in forward
    loss.backward()
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/scratch.ssd/jiribruthans/job_6489502.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn
Using device: cuda
Total parameters: 444,834,925
Trainable parameters: 344,662,125
torch.Size([64, 1280])
Processed 0/15020 cells
Batch processing time: 0.716s
Tokens per second: 91514.90
torch.Size([64, 1280])
Processed 64/15020 cells
Batch processing time: 0.002s
Tokens per second: 29130765.89
torch.Size([64, 1280])
Processed 128/15020 cells
Batch processing time: 0.001s
Tokens per second: 45381856.85
torch.Size([64, 1280])
Processed 192/15020 cells
Batch processing time: 0.001s
Tokens per second: 45989276.72
torch.Size([64, 1280])
Processed 256/15020 cells
Batch processing time: 0.001s
Tokens per second: 45729147.72
torch.Size([64, 1280])
Processed 320/15020 cells
Batch processing time: 0.001s
Tokens per second: 47655670.41
torch.Size([64, 1280])
Processed 384/15020 cells
Batch processing time: 0.001s
Tokens per second: 46636903.11
torch.Size([64, 1280])
Processed 448/15020 cells
Batch processing time: 0.002s
Tokens per second: 42172124.42
torch.Size([64, 1280])
Processed 512/15020 cells
Batch processing time: 0.001s
Tokens per second: 46260166.10
torch.Size([64, 1280])
Processed 576/15020 cells
Batch processing time: 0.001s
Tokens per second: 46907492.65
torch.Size([64, 1280])
Processed 640/15020 cells
Batch processing time: 0.001s
Tokens per second: 46963592.51
torch.Size([64, 1280])
Processed 704/15020 cells
Batch processing time: 0.001s
Tokens per second: 47482796.16
torch.Size([64, 1280])
Processed 768/15020 cells
Batch processing time: 0.176s
Tokens per second: 371592.21
torch.Size([64, 1280])
Processed 832/15020 cells
Batch processing time: 0.604s
Tokens per second: 108507.11
torch.Size([64, 1280])
Processed 896/15020 cells
Batch processing time: 0.583s
Tokens per second: 112504.84
torch.Size([64, 1280])
Processed 960/15020 cells
Batch processing time: 0.608s
Tokens per second: 107759.13
torch.Size([64, 1280])
Processed 1024/15020 cells
Batch processing time: 0.598s
Tokens per second: 109635.02
torch.Size([64, 1280])
Processed 1088/15020 cells
Batch processing time: 0.603s
Tokens per second: 108689.97
torch.Size([64, 1280])
Processed 1152/15020 cells
Batch processing time: 0.602s
Tokens per second: 108859.13
torch.Size([64, 1280])
Processed 1216/15020 cells
Batch processing time: 0.598s
Tokens per second: 109501.90
torch.Size([64, 1280])
Processed 1280/15020 cells
Batch processing time: 0.599s
Tokens per second: 109469.32
torch.Size([64, 1280])
Processed 1344/15020 cells
Batch processing time: 0.600s
Tokens per second: 109243.66
torch.Size([64, 1280])
Processed 1408/15020 cells
Batch processing time: 0.602s
Tokens per second: 108792.48
torch.Size([64, 1280])
Processed 1472/15020 cells
Batch processing time: 0.599s
Tokens per second: 109377.20
torch.Size([64, 1280])
Processed 1536/15020 cells
Batch processing time: 0.598s
Tokens per second: 109543.97
torch.Size([64, 1280])
Processed 1600/15020 cells
Batch processing time: 0.596s
Tokens per second: 110000.49
torch.Size([64, 1280])
Processed 1664/15020 cells
Batch processing time: 0.604s
Tokens per second: 108457.57
torch.Size([64, 1280])
Processed 1728/15020 cells
Batch processing time: 0.601s
Tokens per second: 109029.86
torch.Size([64, 1280])
Processed 1792/15020 cells
Batch processing time: 0.600s
Tokens per second: 109191.02
torch.Size([64, 1280])
Processed 1856/15020 cells
Batch processing time: 0.599s
Tokens per second: 109407.23
torch.Size([64, 1280])
Processed 1920/15020 cells
Batch processing time: 0.601s
Tokens per second: 109075.72
torch.Size([64, 1280])
Processed 1984/15020 cells
Batch processing time: 0.599s
Tokens per second: 109384.86
torch.Size([64, 1280])
Processed 2048/15020 cells
Batch processing time: 0.601s
Tokens per second: 109073.56
torch.Size([64, 1280])
Processed 2112/15020 cells
Batch processing time: 0.601s
Tokens per second: 109103.60
torch.Size([64, 1280])
Processed 2176/15020 cells
Batch processing time: 0.601s
Tokens per second: 109024.50
torch.Size([64, 1280])
Processed 2240/15020 cells
Batch processing time: 0.598s
Tokens per second: 109668.70
torch.Size([64, 1280])
Processed 2304/15020 cells
Batch processing time: 0.602s
Tokens per second: 108856.24
torch.Size([64, 1280])
Processed 2368/15020 cells
Batch processing time: 0.603s
Tokens per second: 108720.62
torch.Size([64, 1280])
Processed 2432/15020 cells
Batch processing time: 0.614s
Tokens per second: 106812.21
torch.Size([64, 1280])
Processed 2496/15020 cells
Batch processing time: 0.602s
Tokens per second: 108866.33
torch.Size([64, 1280])
Processed 2560/15020 cells
Batch processing time: 0.603s
Tokens per second: 108722.90
torch.Size([64, 1280])
Processed 2624/15020 cells
Batch processing time: 0.610s
Tokens per second: 107522.99
torch.Size([64, 1280])
Processed 2688/15020 cells
Batch processing time: 0.607s
Tokens per second: 108048.85
torch.Size([64, 1280])
Processed 2752/15020 cells
Batch processing time: 0.601s
Tokens per second: 108979.24
torch.Size([64, 1280])
Processed 2816/15020 cells
Batch processing time: 0.608s
Tokens per second: 107810.44
torch.Size([64, 1280])
Processed 2880/15020 cells
Batch processing time: 0.592s
Tokens per second: 110619.39
torch.Size([64, 1280])
Processed 2944/15020 cells
Batch processing time: 0.616s
Tokens per second: 106441.78
torch.Size([64, 1280])
Processed 3008/15020 cells
Batch processing time: 0.604s
Tokens per second: 108477.39
torch.Size([64, 1280])
Processed 3072/15020 cells
Batch processing time: 0.615s
Tokens per second: 106533.69
torch.Size([64, 1280])
Processed 3136/15020 cells
Batch processing time: 0.607s
Tokens per second: 107989.55
torch.Size([64, 1280])
Processed 3200/15020 cells
Batch processing time: 0.613s
Tokens per second: 106885.02
torch.Size([64, 1280])
Processed 3264/15020 cells
Batch processing time: 0.612s
Tokens per second: 107151.38
torch.Size([64, 1280])
Processed 3328/15020 cells
Batch processing time: 0.610s
Tokens per second: 107464.23
torch.Size([64, 1280])
Processed 3392/15020 cells
Batch processing time: 0.609s
Tokens per second: 107615.52
torch.Size([64, 1280])
Processed 3456/15020 cells
Batch processing time: 0.611s
Tokens per second: 107195.34
torch.Size([64, 1280])
Processed 3520/15020 cells
Batch processing time: 0.611s
Tokens per second: 107181.38
torch.Size([64, 1280])
Processed 3584/15020 cells
Batch processing time: 0.616s
Tokens per second: 106386.66
torch.Size([64, 1280])
Processed 3648/15020 cells
Batch processing time: 0.611s
Tokens per second: 107244.82
torch.Size([64, 1280])
Processed 3712/15020 cells
Batch processing time: 0.613s
Tokens per second: 106847.29
torch.Size([64, 1280])
Processed 3776/15020 cells
Batch processing time: 0.616s
Tokens per second: 106389.46
torch.Size([64, 1280])
Processed 3840/15020 cells
Batch processing time: 0.608s
Tokens per second: 107861.12
torch.Size([64, 1280])
Processed 3904/15020 cells
Batch processing time: 0.616s
Tokens per second: 106457.40
torch.Size([64, 1280])
Processed 3968/15020 cells
Batch processing time: 0.621s
Tokens per second: 105611.42
torch.Size([64, 1280])
Processed 4032/15020 cells
Batch processing time: 0.611s
Tokens per second: 107256.79
torch.Size([64, 1280])
Processed 4096/15020 cells
Batch processing time: 0.613s
Tokens per second: 106858.22
torch.Size([64, 1280])
Processed 4160/15020 cells
Batch processing time: 0.616s
Tokens per second: 106386.16
torch.Size([64, 1280])
Processed 4224/15020 cells
Batch processing time: 0.617s
Tokens per second: 106281.56
torch.Size([64, 1280])
Processed 4288/15020 cells
Batch processing time: 0.621s
Tokens per second: 105580.83
torch.Size([64, 1280])
Processed 4352/15020 cells
Batch processing time: 0.617s
Tokens per second: 106246.97
torch.Size([64, 1280])
Processed 4416/15020 cells
Batch processing time: 0.620s
Tokens per second: 105768.16
torch.Size([64, 1280])
Processed 4480/15020 cells
Batch processing time: 0.619s
Tokens per second: 105939.65
torch.Size([64, 1280])
Processed 4544/15020 cells
Batch processing time: 0.620s
Tokens per second: 105665.42
torch.Size([64, 1280])
Processed 4608/15020 cells
Batch processing time: 0.621s
Tokens per second: 105498.82
torch.Size([64, 1280])
Processed 4672/15020 cells
Batch processing time: 0.619s
Tokens per second: 105824.80
torch.Size([64, 1280])
Using device: cuda
Total parameters: 444,834,925
Trainable parameters: 344,662,125
torch.Size([64, 1280])
loss: tensor(0.1410, device='cuda:0')
Processed 0/15020 cells
Batch processing time: 0.794s
Tokens per second: 82501.40
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 0.79s
Average tokens per second: 82501.40
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([64, 1280])
loss: 0
Processed 0/15020 cells
Batch processing time: 3.580s
Tokens per second: 18303.64
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 3.58s
Average tokens per second: 18303.64
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
loss: 0
Processed 0/15020 cells
Batch processing time: 3.563s
Tokens per second: 18392.98
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 3.56s
Average tokens per second: 18392.98
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 194, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 169, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 80, in forward
    g_plus = torch.cat((g_plus, embedding), dim=2)
RuntimeError: Tensors must have same number of dimensions: got 3 and 2
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 194, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 169, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 80, in forward
    g_plus = torch.cat((g_plus, embedding.unsqeeeze(0)), dim=2)
AttributeError: 'Tensor' object has no attribute 'unsqeeeze'. Did you mean: 'unsqueeze'?
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 194, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 169, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 80, in forward
    g_plus = torch.cat((g_plus, embedding.unsqeeze(0)), dim=2)
AttributeError: 'Tensor' object has no attribute 'unsqeeze'. Did you mean: 'unsqueeze'?
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 194, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 169, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 80, in forward
    g_plus = torch.cat((g_plus, embedding.unsqueeze(0)), dim=2)
RuntimeError: Sizes of tensors must match except in dimension 2. Expected size 512 but got size 1 for tensor number 1 in the list.
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 196, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 171, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 82, in forward
    g_plus = torch.cat((g_plus, embedding.expand(n_loss, batch_size, token_dim)), dim=2)
NameError: name 'token_dim' is not defined
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 197, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 172, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 83, in forward
    g_plus = torch.cat((g_plus, embedding.expand(self.n_loss, batch_size, self.token_dim)), dim=2)
RuntimeError: The expanded size of the tensor (5120) must match the existing size (1280) at non-singleton dimension 2.  Target sizes: [512, 64, 5120].  Tensor sizes: [64, 1280]
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 6400])
loss: 0
Processed 0/15020 cells
Batch processing time: 3.517s
Tokens per second: 18631.50
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 3.52s
Average tokens per second: 18631.50
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 6400])
loss: 0
Processed 0/15020 cells
Batch processing time: 3.512s
Tokens per second: 18658.39
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 3.51s
Average tokens per second: 18658.39
Using device: cuda
Total parameters: 185,441,280
Trainable parameters: 85,268,480
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 2560])
loss: 0
Processed 0/15020 cells
Batch processing time: 3.489s
Tokens per second: 18783.65
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 3.49s
Average tokens per second: 18783.65
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 214, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 189, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 102, in forward
    loss = cs_loss(g_plus, torch.ones(self.n_loss, dtype=torch.long)) + cs_loss(g_minus, torch.zeros(self.n_loss, dtype=torch.long))
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1293, in forward
    return F.cross_entropy(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/functional.py", line 3479, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
RuntimeError: Expected target size [512, 1], got [512]
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 212, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 187, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 102, in forward
    loss = cs_loss(g_plus, torch.ones(self.n_loss, batch_size, 1, dtype=torch.long)) + cs_loss(g_minus, torch.zeros(self.n_loss, batch_size, 1, dtype=torch.long))
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1293, in forward
    return F.cross_entropy(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/functional.py", line 3479, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
RuntimeError: Expected floating point type for target with class probabilities, got Long
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 212, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 187, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 102, in forward
    loss = cs_loss(g_plus, torch.ones(self.n_loss, batch_size, 1, dtype=torch.float)) + cs_loss(g_minus, torch.zeros(self.n_loss, batch_size, 1, dtype=torch.float))
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1293, in forward
    return F.cross_entropy(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/functional.py", line 3479, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 215, in <module>
    sample_from_model(model)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 190, in sample_from_model
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 104, in forward
    loss = cs_loss(g_plus, torch.ones(self.n_loss, batch_size, 1, dtype=torch.float)) + cs_loss(g_minus, torch.zeros(self.n_loss, batch_size, 1, dtype=torch.float))
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/loss.py", line 1293, in forward
    return F.cross_entropy(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/functional.py", line 3479, in cross_entropy
    return torch._C._nn.cross_entropy_loss(
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
loss: tensor(268.7637, device='cuda:0')
Processed 0/15020 cells
Batch processing time: 3.981s
Tokens per second: 16461.25
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 3.98s
Average tokens per second: 16461.25
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
loss: tensor(266.3016, device='cuda:0')
Processed 0/15020 cells
Batch processing time: 3.998s
Tokens per second: 16393.93
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 4.00s
Average tokens per second: 16393.93
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
loss: tensor(266.2849, device='cuda:0')
Processed 0/15020 cells
Batch processing time: 3.989s
Tokens per second: 16430.30
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 3.99s
Average tokens per second: 16430.30
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
loss: tensor(1.4319, device='cuda:0')
Processed 0/15020 cells
Batch processing time: 3.946s
Tokens per second: 16606.39
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 3.95s
Average tokens per second: 16606.39
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
loss: tensor(1.4109, device='cuda:0')
Processed 0/15020 cells
Batch processing time: 3.993s
Tokens per second: 16412.27
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 3.99s
Average tokens per second: 16412.27
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
loss: tensor(1.3959, device='cuda:0')
Processed 0/15020 cells
Batch processing time: 4.056s
Tokens per second: 16158.77
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 4.06s
Average tokens per second: 16158.77
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 176, in <module>
    cell_emb, loss = forward(batch, current_batch_size)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 164, in forward
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 85, in forward
    output = self.transformer_encoder(src)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 511, in forward
    output = mod(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 904, in forward
    + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 918, in _sa_block
    x = self.self_attn(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1368, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/functional.py", line 6097, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/functional.py", line 5508, in _in_projection_packed
    .contiguous()
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 960.00 MiB. GPU 0 has a total capacity of 14.57 GiB of which 724.75 MiB is free. Including non-PyTorch memory, this process has 13.86 GiB memory in use. Of the allocated memory 13.24 GiB is allocated by PyTorch, and 504.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
loss: tensor(0.7008, device='cuda:0')
Processed 0/15020 cells
Batch processing time: 4.051s
Tokens per second: 16178.82
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 4.05s
Average tokens per second: 16178.82
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
torch.Size([64, 1280])
g_plus shape: torch.Size([512, 64, 1])
loss: tensor(0.7283, device='cuda:0')
Processed 0/15020 cells
Batch processing time: 4.052s
Tokens per second: 16174.88
Final embeddings shape: torch.Size([64, 1280])
Total processing time: 4.05s
Average tokens per second: 16174.88
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 64, 5120])
torch.Size([512, 64, 5120])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 180, in <module>
    cell_emb, loss = forward(batch, current_batch_size)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 154, in forward
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 85, in forward
    output = self.transformer_encoder(src)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 511, in forward
    output = mod(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 904, in forward
    + self._sa_block(x, src_mask, src_key_padding_mask, is_causal=is_causal)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 918, in _sa_block
    x = self.self_attn(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 1368, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/functional.py", line 6097, in multi_head_attention_forward
    q, k, v = _in_projection_packed(query, key, value, in_proj_weight, in_proj_bias)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/functional.py", line 5508, in _in_projection_packed
    .contiguous()
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 960.00 MiB. GPU 0 has a total capacity of 14.57 GiB of which 724.75 MiB is free. Including non-PyTorch memory, this process has 13.86 GiB memory in use. Of the allocated memory 13.24 GiB is allocated by PyTorch, and 504.41 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 32, 5120])
torch.Size([512, 32, 5120])
Traceback (most recent call last):
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 180, in <module>
    cell_emb, loss = forward(batch, current_batch_size)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 154, in forward
    cell_emb, loss = model(batch, g_plus, g_minus)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/transcriptome_encoder/train_model.py", line 85, in forward
    output = self.transformer_encoder(src)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 511, in forward
    output = mod(
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 906, in forward
    x = self.norm2(x + self._ff_block(x))
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 931, in _ff_block
    x = self.linear2(self.dropout(self.activation(self.linear1(x))))
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/scratch.ssd/jiribruthans/job_6492426.pbs-m1.metacentrum.cz/miniforge3/envs/txn-enc/lib/python3.10/site-packages/torch/nn/modules/linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 640.00 MiB. GPU 0 has a total capacity of 14.57 GiB of which 404.75 MiB is free. Including non-PyTorch memory, this process has 14.17 GiB memory in use. Of the allocated memory 13.99 GiB is allocated by PyTorch, and 58.80 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.7547883987426758 for step 0
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 1.1863787174224854 for step 1
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6928627490997314 for step 2
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.7321984767913818 for step 3
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6932337880134583 for step 4
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.694608211517334 for step 5
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.7024076581001282 for step 6
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6965687870979309 for step 7
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6917989253997803 for step 8
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6899523138999939 for step 9
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6908093094825745 for step 10
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6929230690002441 for step 11
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6929274797439575 for step 12
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6915003657341003 for step 13
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6894291639328003 for step 14
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6885641813278198 for step 15
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6883547306060791 for step 16
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6880240440368652 for step 17
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6887542009353638 for step 18
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6883552074432373 for step 19
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6872034668922424 for step 20
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6853305101394653 for step 21
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.683367133140564 for step 22
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6818066835403442 for step 23
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.680266261100769 for step 24
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6801720857620239 for step 25
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6771920919418335 for step 26
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6740333437919617 for step 27
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6689505577087402 for step 28
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6644858121871948 for step 29
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.659544825553894 for step 30
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6529284715652466 for step 31
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6430070400238037 for step 32
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6363284587860107 for step 33
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.630991518497467 for step 34
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6324177384376526 for step 35
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6322884559631348 for step 36
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6335788369178772 for step 37
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6210218667984009 for step 38
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6229307055473328 for step 39
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6209483742713928 for step 40
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6177492141723633 for step 41
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.614527702331543 for step 42
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6093921661376953 for step 43
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6093780398368835 for step 44
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6074850559234619 for step 45
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6002998352050781 for step 46
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.6000175476074219 for step 47
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.5978828072547913 for step 48
torch.Size([512, 16, 5120])
torch.Size([512, 16, 5120])
torch.Size([16, 1280])
g_plus shape: torch.Size([512, 16, 1])
loss: 0.5886073708534241 for step 49
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
loss: 0.7123446464538574 for step 0
loss: 1.1905572414398193 for step 1
loss: 0.7018802762031555 for step 2
loss: 0.7198768854141235 for step 3
loss: 0.7030426263809204 for step 4
loss: 0.6901713609695435 for step 5
loss: 0.6923319101333618 for step 6
loss: 0.6953984498977661 for step 7
loss: 0.6926589012145996 for step 8
loss: 0.6887415647506714 for step 9
loss: 0.6870466470718384 for step 10
loss: 0.6859828233718872 for step 11
loss: 0.6866031885147095 for step 12
loss: 0.6871229410171509 for step 13
loss: 0.6852671504020691 for step 14
loss: 0.6821700930595398 for step 15
loss: 0.6803898811340332 for step 16
loss: 0.6786451935768127 for step 17
loss: 0.6752707958221436 for step 18
loss: 0.6721924543380737 for step 19
loss: 0.6658793687820435 for step 20
loss: 0.6589656472206116 for step 21
loss: 0.6551899313926697 for step 22
loss: 0.6456183195114136 for step 23
loss: 0.6443223357200623 for step 24
loss: 0.6380395293235779 for step 25
loss: 0.6349661350250244 for step 26
loss: 0.6247704029083252 for step 27
loss: 0.6212505102157593 for step 28
loss: 0.6286192536354065 for step 29
loss: 0.6151365041732788 for step 30
loss: 0.622306764125824 for step 31
loss: 0.6152603626251221 for step 32
loss: 0.6120929718017578 for step 33
loss: 0.6119218468666077 for step 34
loss: 0.6163473129272461 for step 35
loss: 0.6033236980438232 for step 36
loss: 0.6028200387954712 for step 37
loss: 0.6012431383132935 for step 38
loss: 0.5980503559112549 for step 39
loss: 0.5882958173751831 for step 40
loss: 0.5922353863716125 for step 41
loss: 0.5867172479629517 for step 42
loss: 0.58958899974823 for step 43
loss: 0.5939871072769165 for step 44
loss: 0.5844380259513855 for step 45
loss: 0.5849952697753906 for step 46
loss: 0.5914216637611389 for step 47
loss: 0.5796923637390137 for step 48
loss: 0.5865311026573181 for step 49
Using device: cuda
Total parameters: 191,806,465
Trainable parameters: 91,633,665
loss: 0.7042100429534912 for step 0
loss: 1.1451719999313354 for step 1
loss: 0.682401180267334 for step 2
loss: 0.6859777569770813 for step 3
loss: 0.6755377054214478 for step 4
loss: 0.6694540977478027 for step 5
loss: 0.6595202088356018 for step 6
loss: 0.6517429351806641 for step 7
loss: 0.6461935043334961 for step 8
loss: 0.6332727670669556 for step 9
loss: 0.630662202835083 for step 10
loss: 0.6456760168075562 for step 11
loss: 0.6389737129211426 for step 12
loss: 0.6249110698699951 for step 13
loss: 0.630912184715271 for step 14
loss: 0.6195226907730103 for step 15
loss: 0.6224956512451172 for step 16
loss: 0.618640661239624 for step 17
loss: 0.6181625127792358 for step 18
loss: 0.614814817905426 for step 19
loss: 0.61924809217453 for step 20
loss: 0.6119582653045654 for step 21
loss: 0.6060453057289124 for step 22
loss: 0.6054017543792725 for step 23
loss: 0.6011333465576172 for step 24
loss: 0.6022330522537231 for step 25
loss: 0.5973576307296753 for step 26
loss: 0.603069007396698 for step 27
loss: 0.5913187861442566 for step 28
loss: 0.5938723683357239 for step 29
loss: 0.5921255350112915 for step 30
loss: 0.584578275680542 for step 31
loss: 0.5905260443687439 for step 32
loss: 0.586860179901123 for step 33
loss: 0.5846008062362671 for step 34
loss: 0.5813612341880798 for step 35
loss: 0.5811218023300171 for step 36
loss: 0.5848164558410645 for step 37
loss: 0.5734587907791138 for step 38
loss: 0.5813260674476624 for step 39
loss: 0.5699514746665955 for step 40
loss: 0.5739343166351318 for step 41
loss: 0.575138509273529 for step 42
loss: 0.5716385841369629 for step 43
loss: 0.567802369594574 for step 44
loss: 0.5665872097015381 for step 45
loss: 0.570772647857666 for step 46
loss: 0.5689382553100586 for step 47
loss: 0.5721887350082397 for step 48
loss: 0.5703731179237366 for step 49
loss: 0.5668401122093201 for step 50
loss: 0.5682610869407654 for step 51
loss: 0.5745866298675537 for step 52
loss: 0.563496470451355 for step 53
loss: 0.5647594928741455 for step 54
loss: 0.5641130208969116 for step 55
loss: 0.5633211731910706 for step 56
loss: 0.5623368620872498 for step 57
loss: 0.5584060549736023 for step 58
loss: 0.5675768852233887 for step 59
loss: 0.5849794745445251 for step 60
loss: 0.5706251263618469 for step 61
loss: 0.5642821788787842 for step 62
loss: 0.5613577961921692 for step 63
loss: 0.568138062953949 for step 64
loss: 0.5623083114624023 for step 65
loss: 0.5629110336303711 for step 66
loss: 0.5606423020362854 for step 67
loss: 0.5588111877441406 for step 68
loss: 0.5612401962280273 for step 69
loss: 0.5648598074913025 for step 70
loss: 0.5561397075653076 for step 71
loss: 0.5475957989692688 for step 72
loss: 0.5600855946540833 for step 73
loss: 0.5576695203781128 for step 74
loss: 0.5598343014717102 for step 75
loss: 0.5560494661331177 for step 76
loss: 0.5524131059646606 for step 77
loss: 0.5589469075202942 for step 78
loss: 0.5497314929962158 for step 79
loss: 0.5485666990280151 for step 80
loss: 0.5531408190727234 for step 81
loss: 0.556002140045166 for step 82
loss: 0.5464204549789429 for step 83
loss: 0.5449188947677612 for step 84
loss: 0.5510187149047852 for step 85
loss: 0.5535513162612915 for step 86
loss: 0.5568428039550781 for step 87
loss: 0.5488952994346619 for step 88
loss: 0.5478978157043457 for step 89
loss: 0.554419755935669 for step 90
loss: 0.5405957102775574 for step 91
loss: 0.5422812104225159 for step 92
loss: 0.5355715751647949 for step 93
loss: 0.5449402332305908 for step 94
loss: 0.5518196821212769 for step 95
loss: 0.5423213243484497 for step 96
loss: 0.544878363609314 for step 97
loss: 0.5453534722328186 for step 98
loss: 0.5490509867668152 for step 99
loss: 0.566056489944458 for step 100
loss: 0.5465455055236816 for step 101
loss: 0.5573237538337708 for step 102
loss: 0.5589402914047241 for step 103
loss: 0.5412806272506714 for step 104
loss: 0.5542452335357666 for step 105
loss: 0.5611073970794678 for step 106
loss: 0.5371335744857788 for step 107
loss: 0.554625928401947 for step 108
loss: 0.5486723184585571 for step 109
loss: 0.5465528964996338 for step 110
loss: 0.5512966513633728 for step 111
loss: 0.5368251800537109 for step 112
loss: 0.5516343116760254 for step 113
loss: 0.541613757610321 for step 114
loss: 0.5360994935035706 for step 115
loss: 0.5318331718444824 for step 116
loss: 0.5296325087547302 for step 117
loss: 0.5452581644058228 for step 118
loss: 0.5415639877319336 for step 119
loss: 0.5387433171272278 for step 120
loss: 0.5394463539123535 for step 121
loss: 0.5328477621078491 for step 122
loss: 0.5348023176193237 for step 123
loss: 0.5354819893836975 for step 124
loss: 0.5514199137687683 for step 125
loss: 0.540690004825592 for step 126
loss: 0.5396431088447571 for step 127
loss: 0.5484733581542969 for step 128
loss: 0.5344491600990295 for step 129
loss: 0.5457665920257568 for step 130
loss: 0.5733565092086792 for step 131
loss: 0.5532299876213074 for step 132
loss: 0.5625113844871521 for step 133
loss: 0.5442297458648682 for step 134
loss: 0.5487937331199646 for step 135
loss: 0.5434029698371887 for step 136
loss: 0.5577894449234009 for step 137
loss: 0.5373995304107666 for step 138
loss: 0.5462073683738708 for step 139
loss: 0.5374190807342529 for step 140
loss: 0.5455981492996216 for step 141
loss: 0.534623384475708 for step 142
loss: 0.5558024644851685 for step 143
loss: 0.533906102180481 for step 144
loss: 0.5522051453590393 for step 145
loss: 0.5443953275680542 for step 146
loss: 0.5487259030342102 for step 147
loss: 0.5386995673179626 for step 148
loss: 0.5439783930778503 for step 149
loss: 0.5344499945640564 for step 150
loss: 0.5441279411315918 for step 151
loss: 0.5352218151092529 for step 152
loss: 0.5372607707977295 for step 153
loss: 0.5285330414772034 for step 154
loss: 0.5361902713775635 for step 155
loss: 0.5248410701751709 for step 156
loss: 0.527499794960022 for step 157
loss: 0.5299839973449707 for step 158
loss: 0.5332214832305908 for step 159
loss: 0.5237327814102173 for step 160
loss: 0.5239822268486023 for step 161
loss: 0.5275466442108154 for step 162
loss: 0.5229964256286621 for step 163
loss: 0.5143964290618896 for step 164
loss: 0.5192744135856628 for step 165
loss: 0.5266852974891663 for step 166
loss: 0.5248685479164124 for step 167
loss: 0.5313663482666016 for step 168
loss: 0.5249965190887451 for step 169
loss: 0.5232497453689575 for step 170
loss: 0.5309441685676575 for step 171
loss: 0.5234948396682739 for step 172
loss: 0.5271341800689697 for step 173
loss: 0.5233269929885864 for step 174
loss: 0.5204207897186279 for step 175
loss: 0.5262451171875 for step 176
loss: 0.522130012512207 for step 177
loss: 0.5242023468017578 for step 178
loss: 0.5223338603973389 for step 179
loss: 0.5181072950363159 for step 180
loss: 0.5225073099136353 for step 181
loss: 0.5176283717155457 for step 182
loss: 0.5186625719070435 for step 183
loss: 0.5224714279174805 for step 184
loss: 0.5202322006225586 for step 185
loss: 0.5318767428398132 for step 186
loss: 0.5211659669876099 for step 187
loss: 0.5215669870376587 for step 188
loss: 0.5310593843460083 for step 189
loss: 0.5216405987739563 for step 190
loss: 0.5194708108901978 for step 191
loss: 0.5300275683403015 for step 192
loss: 0.5326415300369263 for step 193
loss: 0.5368375778198242 for step 194
loss: 0.5325609445571899 for step 195
loss: 0.5262293219566345 for step 196
loss: 0.5252496004104614 for step 197
loss: 0.5184808373451233 for step 198
loss: 0.5322484970092773 for step 199
loss: 0.5220233201980591 for step 200
loss: 0.5272491574287415 for step 201
loss: 0.5326246023178101 for step 202
loss: 0.5301371216773987 for step 203
loss: 0.5208584070205688 for step 204
loss: 0.5240920186042786 for step 205
loss: 0.5173940658569336 for step 206
loss: 0.5158801078796387 for step 207
loss: 0.520808219909668 for step 208
loss: 0.51384437084198 for step 209
loss: 0.5211215019226074 for step 210
loss: 0.5205086469650269 for step 211
loss: 0.5083804130554199 for step 212
loss: 0.5088986754417419 for step 213
loss: 0.5272951126098633 for step 214
loss: 0.5263248682022095 for step 215
loss: 0.531242311000824 for step 216
loss: 0.5203630924224854 for step 217
loss: 0.5177497267723083 for step 218
loss: 0.5345338582992554 for step 219
loss: 0.5175676941871643 for step 220
loss: 0.5309508442878723 for step 221
loss: 0.5210223197937012 for step 222
loss: 0.5305727124214172 for step 223
loss: 0.5553454160690308 for step 224
loss: 0.5720005035400391 for step 225
loss: 0.6005815267562866 for step 226
loss: 0.5917218923568726 for step 227
loss: 0.5917606949806213 for step 228
loss: 0.5886317491531372 for step 229
loss: 0.5718719959259033 for step 230
loss: 0.5451403856277466 for step 231
loss: 0.5711353421211243 for step 232
loss: 0.5492082834243774 for step 233
loss: 0.5624719262123108 for step 234
loss: 0.5416107177734375 for step 235
loss: 0.5529391765594482 for step 236
loss: 0.5282720327377319 for step 237
loss: 0.5509533286094666 for step 238
loss: 0.5340413451194763 for step 239
loss: 0.5389787554740906 for step 240
loss: 0.5486761331558228 for step 241
loss: 0.5326952338218689 for step 242
loss: 0.5409957766532898 for step 243
loss: 0.5318946838378906 for step 244
loss: 0.5350033044815063 for step 245
loss: 0.5308719873428345 for step 246
loss: 0.5319620966911316 for step 247
loss: 0.5255798101425171 for step 248
loss: 0.5200098156929016 for step 249
loss: 0.5228685140609741 for step 250
loss: 0.5205349922180176 for step 251
loss: 0.518439531326294 for step 252
loss: 0.5175950527191162 for step 253
loss: 0.5125501155853271 for step 254
loss: 0.5183375477790833 for step 255
loss: 0.5133687257766724 for step 256
loss: 0.5191667079925537 for step 257
loss: 0.5249015688896179 for step 258
loss: 0.5190896987915039 for step 259
loss: 0.5175617933273315 for step 260
loss: 0.5170325040817261 for step 261
loss: 0.5127304792404175 for step 262
loss: 0.5191708207130432 for step 263
loss: 0.5119017362594604 for step 264
loss: 0.510464072227478 for step 265
loss: 0.516208827495575 for step 266
loss: 0.5126679539680481 for step 267
loss: 0.509621262550354 for step 268
loss: 0.5200343132019043 for step 269
loss: 0.5150326490402222 for step 270
loss: 0.5129612684249878 for step 271
loss: 0.5048140287399292 for step 272
loss: 0.5146769285202026 for step 273
loss: 0.5126608610153198 for step 274
loss: 0.5143299102783203 for step 275
loss: 0.510261595249176 for step 276
loss: 0.5103343725204468 for step 277
loss: 0.5102035403251648 for step 278
loss: 0.509115993976593 for step 279
loss: 0.5020078420639038 for step 280
loss: 0.5085816979408264 for step 281
loss: 0.5084675550460815 for step 282
loss: 0.49983471632003784 for step 283
loss: 0.5052586793899536 for step 284
loss: 0.5082848072052002 for step 285
loss: 0.5084612369537354 for step 286
loss: 0.5052878856658936 for step 287
loss: 0.5090678930282593 for step 288
loss: 0.5050780177116394 for step 289
loss: 0.502943754196167 for step 290
loss: 0.5052984952926636 for step 291
loss: 0.5056216716766357 for step 292
loss: 0.5177556276321411 for step 293
loss: 0.5249353647232056 for step 294
loss: 0.5201857089996338 for step 295
loss: 0.5149844884872437 for step 296
loss: 0.5199331045150757 for step 297
loss: 0.514312744140625 for step 298
loss: 0.5063307881355286 for step 299
loss: 0.5179681777954102 for step 300
loss: 0.5058503746986389 for step 301
loss: 0.5108630061149597 for step 302
loss: 0.5296186804771423 for step 303
loss: 0.5216220617294312 for step 304
loss: 0.5103130340576172 for step 305
loss: 0.5320147275924683 for step 306
loss: 0.5165586471557617 for step 307
loss: 0.512037992477417 for step 308
loss: 0.53425532579422 for step 309
loss: 0.5239080786705017 for step 310
loss: 0.5248812437057495 for step 311
loss: 0.5189101099967957 for step 312
loss: 0.5280544757843018 for step 313
loss: 0.5258914232254028 for step 314
loss: 0.5041307806968689 for step 315
loss: 0.5179585218429565 for step 316
loss: 0.5074877738952637 for step 317
loss: 0.5180638432502747 for step 318
loss: 0.5127261281013489 for step 319
loss: 0.5094822645187378 for step 320
loss: 0.514776885509491 for step 321
loss: 0.5038691163063049 for step 322
loss: 0.5190051794052124 for step 323
loss: 0.5045034885406494 for step 324
loss: 0.5100988745689392 for step 325
loss: 0.49698907136917114 for step 326
loss: 0.5067217946052551 for step 327
loss: 0.5033280253410339 for step 328
loss: 0.49825793504714966 for step 329
loss: 0.4982500672340393 for step 330
loss: 0.4965258240699768 for step 331
loss: 0.5027119517326355 for step 332
loss: 0.4972221553325653 for step 333
loss: 0.49873754382133484 for step 334
loss: 0.4936348795890808 for step 335
loss: 0.49993661046028137 for step 336
loss: 0.5043853521347046 for step 337
loss: 0.5093268156051636 for step 338
loss: 0.49525514245033264 for step 339
loss: 0.5044012069702148 for step 340
loss: 0.5301990509033203 for step 341
loss: 0.5136375427246094 for step 342
loss: 0.5370171070098877 for step 343
loss: 0.5137618780136108 for step 344
loss: 0.5243422985076904 for step 345
loss: 0.5152422189712524 for step 346
loss: 0.5355350375175476 for step 347
loss: 0.5176211595535278 for step 348
loss: 0.5368499159812927 for step 349
loss: 0.5142696499824524 for step 350
loss: 0.5120639801025391 for step 351
loss: 0.5108453035354614 for step 352
loss: 0.5246695280075073 for step 353
loss: 0.5234438180923462 for step 354
loss: 0.521373987197876 for step 355
loss: 0.5189226865768433 for step 356
loss: 0.515755295753479 for step 357
loss: 0.4963374137878418 for step 358
loss: 0.5397539138793945 for step 359
loss: 0.5250114798545837 for step 360
loss: 0.5144265294075012 for step 361
loss: 0.5267470479011536 for step 362
loss: 0.529924750328064 for step 363
loss: 0.5076488852500916 for step 364
loss: 0.51014643907547 for step 365
loss: 0.5014705061912537 for step 366
loss: 0.527247428894043 for step 367
loss: 0.5061378479003906 for step 368
loss: 0.5084760785102844 for step 369
loss: 0.5053110122680664 for step 370
loss: 0.5147027969360352 for step 371
loss: 0.50071120262146 for step 372
loss: 0.509355366230011 for step 373
loss: 0.5076059103012085 for step 374
loss: 0.5054317116737366 for step 375
loss: 0.49861225485801697 for step 376
loss: 0.5047390460968018 for step 377
loss: 0.5034757852554321 for step 378
loss: 0.5155647993087769 for step 379
loss: 0.5004492998123169 for step 380
loss: 0.5079658627510071 for step 381
loss: 0.49896296858787537 for step 382
loss: 0.508223295211792 for step 383
loss: 0.5050359964370728 for step 384
loss: 0.5046660900115967 for step 385
loss: 0.5001740455627441 for step 386
loss: 0.5061052441596985 for step 387
loss: 0.5061079263687134 for step 388
loss: 0.4972301721572876 for step 389
loss: 0.49850940704345703 for step 390
loss: 0.4976465106010437 for step 391
loss: 0.49872976541519165 for step 392
loss: 0.503278374671936 for step 393
loss: 0.5023175477981567 for step 394
loss: 0.5024253129959106 for step 395
loss: 0.4955369830131531 for step 396
loss: 0.5056124925613403 for step 397
loss: 0.49160265922546387 for step 398
loss: 0.4948744773864746 for step 399
loss: 0.5068671107292175 for step 400
loss: 0.49151208996772766 for step 401
loss: 0.49833282828330994 for step 402
loss: 0.4887596070766449 for step 403
loss: 0.49687397480010986 for step 404
loss: 0.49347826838493347 for step 405
loss: 0.4901036322116852 for step 406
loss: 0.49062299728393555 for step 407
loss: 0.4923550486564636 for step 408
loss: 0.48991137742996216 for step 409
loss: 0.4930696487426758 for step 410
loss: 0.4914343059062958 for step 411
loss: 0.49334716796875 for step 412
loss: 0.49532145261764526 for step 413
loss: 0.4979657530784607 for step 414
loss: 0.49549105763435364 for step 415
loss: 0.4909747540950775 for step 416
loss: 0.49361228942871094 for step 417
loss: 0.49442803859710693 for step 418
loss: 0.49245980381965637 for step 419
loss: 0.4888220429420471 for step 420
loss: 0.4903841018676758 for step 421
loss: 0.4973686635494232 for step 422
loss: 0.4983759820461273 for step 423
loss: 0.4933437705039978 for step 424
loss: 0.4929714798927307 for step 425
loss: 0.4940328001976013 for step 426
loss: 0.489889919757843 for step 427
loss: 0.49460846185684204 for step 428
loss: 0.48640769720077515 for step 429
loss: 0.4904780387878418 for step 430
loss: 0.5241937637329102 for step 431
loss: 0.5576976537704468 for step 432
loss: 0.5539920330047607 for step 433
loss: 0.5318642258644104 for step 434
loss: 0.5317531228065491 for step 435
loss: 0.5279440879821777 for step 436
loss: 0.5270718932151794 for step 437
loss: 0.5005908012390137 for step 438
loss: 0.5189322233200073 for step 439
loss: 0.518165111541748 for step 440
loss: 0.5115135908126831 for step 441
loss: 0.5042636394500732 for step 442
loss: 0.5173091888427734 for step 443
loss: 0.5025231838226318 for step 444
loss: 0.5013036727905273 for step 445
loss: 0.5028688311576843 for step 446
loss: 0.5076451301574707 for step 447
loss: 0.5009002685546875 for step 448
loss: 0.5058186054229736 for step 449
loss: 0.5021154284477234 for step 450
loss: 0.49287867546081543 for step 451
loss: 0.4880197048187256 for step 452
loss: 0.4915863275527954 for step 453
loss: 0.4983258545398712 for step 454
loss: 0.49580150842666626 for step 455
loss: 0.49800264835357666 for step 456
loss: 0.49110954999923706 for step 457
loss: 0.49556219577789307 for step 458
loss: 0.4984806180000305 for step 459
loss: 0.4955485761165619 for step 460
loss: 0.48904094099998474 for step 461
loss: 0.49118247628211975 for step 462
loss: 0.48694613575935364 for step 463
loss: 0.48966628313064575 for step 464
loss: 0.4882275462150574 for step 465
loss: 0.4893531799316406 for step 466
loss: 0.49018576741218567 for step 467
loss: 0.48572757840156555 for step 468
loss: 0.48383626341819763 for step 469
loss: 0.48392531275749207 for step 470
loss: 0.48082125186920166 for step 471
loss: 0.48444482684135437 for step 472
loss: 0.4855417311191559 for step 473
loss: 0.4950144588947296 for step 474
loss: 0.4845890998840332 for step 475
loss: 0.48064684867858887 for step 476
loss: 0.4923228621482849 for step 477
loss: 0.491496741771698 for step 478
loss: 0.49120908975601196 for step 479
loss: 0.4930921792984009 for step 480
loss: 0.48633700609207153 for step 481
loss: 0.48268094658851624 for step 482
loss: 0.49073857069015503 for step 483
loss: 0.4876359701156616 for step 484
loss: 0.49356693029403687 for step 485
loss: 0.5012587308883667 for step 486
loss: 0.489804744720459 for step 487
loss: 0.4865807294845581 for step 488
loss: 0.4918578863143921 for step 489
loss: 0.4978557825088501 for step 490
loss: 0.49458104372024536 for step 491
loss: 0.494379460811615 for step 492
loss: 0.4938849210739136 for step 493
loss: 0.49370330572128296 for step 494
loss: 0.4951742887496948 for step 495
loss: 0.4851765036582947 for step 496
loss: 0.4971734285354614 for step 497
loss: 0.4911171793937683 for step 498
loss: 0.48338574171066284 for step 499
